{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "LÃª os dados:"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df = pd.read_csv(\"Base_Dissertacaov10.csv\",sep=';',decimal=\",\",encoding = \"latin\")\n",
    "# print(df.head())"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "from sklearn import preprocessing\n",
    "from sklearn.model_selection import train_test_split\n",
    "#Cria os dados\n",
    "y = df[\"AUTO\"].to_numpy()\n",
    "X = df.iloc[:,3:-1]\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state = 12345)\n",
    "\n",
    "#Padroniza os dados\n",
    "scaler = preprocessing.StandardScaler().fit(X_train)\n",
    "X_train = scaler.transform(X_train)\n",
    "X_test = scaler.transform(X_test)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Random Over Sampler"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "from imblearn.over_sampling import RandomOverSampler\n",
    "ros = RandomOverSampler(random_state=12345)\n",
    "X_resampled, y_resampled = ros.fit_resample(X_train, y_train)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Accuracy Score: 0.9943872778297475\n",
      " Precision Score: [0.99438728 0.        ]\n",
      " Recall Score: [1. 0.]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/pedro/Library/Python/3.7/lib/python/site-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score\n",
    "logreg = LogisticRegression(solver = 'lbfgs', multi_class = 'auto')\n",
    "logreg.fit(X_train, y_train)\n",
    "y_pred = logreg.predict(X_test)\n",
    "print(f' Accuracy Score: {accuracy_score(y_test, y_pred)}')\n",
    "print(f' Precision Score: {precision_score(y_test, y_pred, average = None)}')\n",
    "print(f' Recall Score: {recall_score(y_test, y_pred, average = None)}')\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Random Over Sampler\n",
    "Copiado de : https://audreymychan.com/unbalancedclasses.html"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [],
   "source": [
    "# Method to rebalance train data, model a logistic regression, and output charts for predictions on test data\n",
    "# Inputs: X data, y data, rebalance algorithm (i.e. SMOTE()), rebalancing_title as a str (i.e. 'SMOTE')\n",
    "from imblearn.metrics import classification_report_imbalanced, sensitivity_specificity_support,sensitivity_score,specificity_score,geometric_mean_score, make_index_balanced_accuracy\n",
    "def rebalance_train_test_logreg(X, y, rebalance_alg, rebalancing_title, test_size=0.1):\n",
    "\n",
    "    # Split the data\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = test_size, random_state = 12345)\n",
    "    scaler = preprocessing.StandardScaler().fit(X_train)\n",
    "    X_train = scaler.transform(X_train)\n",
    "    X_test = scaler.transform(X_test)\n",
    "\n",
    "    # Rebalance train data\n",
    "    rebalance = rebalance_alg\n",
    "    X_reb, y_reb = rebalance.fit_sample(X_train, y_train)\n",
    "\n",
    "    # Train a Logistic Regression model on resampled data\n",
    "    logreg = LogisticRegression(solver = 'lbfgs', multi_class = 'auto')\n",
    "    logreg.fit(X_reb, y_reb)\n",
    "\n",
    "    # Generate predictions\n",
    "    y_pred = logreg.predict(X_test)\n",
    "\n",
    "    # Print out metrics\n",
    "    print(f'-------------------------------{rebalancing_title} test size={test_size}--------------------------------------')\n",
    "    print(\"----------   Standard Metrics   -------------------\")\n",
    "    print(f' Accuracy Score: {accuracy_score(y_test, y_pred)}')\n",
    "    print(f' Precision Score: {precision_score(y_test, y_pred, average = None)}')\n",
    "    print(f' Recall Score: {recall_score(y_test, y_pred, average = None)}')\n",
    "    print(\"----------   Imbalanced Metrics   -------------------\")\n",
    "    print(f' Classification report imbalanced: {classification_report_imbalanced(y_test, y_pred)}')\n",
    "    print(f' Sensitivity specificity support:')\n",
    "    print(sensitivity_specificity_support(y_test, y_pred))\n",
    "    print(f' Sensitivity score: {sensitivity_score(y_test, y_pred)}')\n",
    "    print(f' Specificity score: {specificity_score(y_test, y_pred)}')\n",
    "    print(f' Geometric mean score: {geometric_mean_score(y_test, y_pred)}')\n",
    "\n",
    "    return None\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# ClusterCentroids"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------------------ClusterCentroids test size=0.1--------------------------------------\n",
      "----------   Standard Metrics   -------------------\n",
      " Accuracy Score: 0.8185785536159601\n",
      " Precision Score: [0.99770467 0.03030303]\n",
      " Recall Score: [0.81909548 0.75      ]\n",
      "----------   Imbalanced Metrics   -------------------\n",
      " Classification report imbalanced:                    pre       rec       spe        f1       geo       iba       sup\n",
      "\n",
      "          0       1.00      0.82      0.75      0.90      0.78      0.62      1592\n",
      "          1       0.03      0.75      0.82      0.06      0.78      0.61        12\n",
      "\n",
      "avg / total       0.99      0.82      0.75      0.89      0.78      0.62      1604\n",
      "\n",
      " Sensitivity specificity support:\n",
      "(array([0.81909548, 0.75      ]), array([0.75      , 0.81909548]), array([1592,   12]))\n",
      " Sensitivity score: 0.75\n",
      " Specificity score: 0.8190954773869347\n",
      " Geometric mean score: 0.7837867108086236\n"
     ]
    }
   ],
   "source": [
    "test_size=0.1\n",
    "try:\n",
    "    from imblearn.under_sampling import ClusterCentroids\n",
    "    rebalance_train_test_logreg(X, y, ClusterCentroids(), 'ClusterCentroids',test_size)\n",
    "except:\n",
    "    print(\"Erro!\")\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# CondensedNearestNeighbour"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------------------CondensedNearestNeighbour test size=0.1--------------------------------------\n",
      "----------   Standard Metrics   -------------------\n",
      " Accuracy Score: 0.9918952618453866\n",
      " Precision Score: [0.99251404 0.        ]\n",
      " Recall Score: [0.99937186 0.        ]\n",
      "----------   Imbalanced Metrics   -------------------\n",
      " Classification report imbalanced:                    pre       rec       spe        f1       geo       iba       sup\n",
      "\n",
      "          0       0.99      1.00      0.00      1.00      0.00      0.00      1592\n",
      "          1       0.00      0.00      1.00      0.00      0.00      0.00        12\n",
      "\n",
      "avg / total       0.99      0.99      0.01      0.99      0.00      0.00      1604\n",
      "\n",
      " Sensitivity specificity support:\n",
      "(array([0.99937186, 0.        ]), array([0.        , 0.99937186]), array([1592,   12]))\n",
      " Sensitivity score: 0.0\n",
      " Specificity score: 0.9993718592964824\n",
      " Geometric mean score: 0.0\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    from imblearn.under_sampling import CondensedNearestNeighbour\n",
    "    rebalance_train_test_logreg(X, y, CondensedNearestNeighbour(), 'CondensedNearestNeighbour',test_size)\n",
    "except:\n",
    "    print(\"Erro!\")\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# EditedNearestNeighbours"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------------------EditedNearestNeighbours test size=0.1--------------------------------------\n",
      "----------   Standard Metrics   -------------------\n",
      " Accuracy Score: 0.9918952618453866\n",
      " Precision Score: [0.99251404 0.        ]\n",
      " Recall Score: [0.99937186 0.        ]\n",
      "----------   Imbalanced Metrics   -------------------\n",
      " Classification report imbalanced:                    pre       rec       spe        f1       geo       iba       sup\n",
      "\n",
      "          0       0.99      1.00      0.00      1.00      0.00      0.00      1592\n",
      "          1       0.00      0.00      1.00      0.00      0.00      0.00        12\n",
      "\n",
      "avg / total       0.99      0.99      0.01      0.99      0.00      0.00      1604\n",
      "\n",
      " Sensitivity specificity support:\n",
      "(array([0.99937186, 0.        ]), array([0.        , 0.99937186]), array([1592,   12]))\n",
      " Sensitivity score: 0.0\n",
      " Specificity score: 0.9993718592964824\n",
      " Geometric mean score: 0.0\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    from imblearn.under_sampling import EditedNearestNeighbours\n",
    "    rebalance_train_test_logreg(X, y, EditedNearestNeighbours(), 'EditedNearestNeighbours',test_size)\n",
    "except:\n",
    "    print(\"Erro!\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# EditedNearestNeighbours"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------------------RepeatedEditedNearestNeighbours test size=0.1--------------------------------------\n",
      "----------   Standard Metrics   -------------------\n",
      " Accuracy Score: 0.9918952618453866\n",
      " Precision Score: [0.99312929 0.33333333]\n",
      " Recall Score: [0.99874372 0.08333333]\n",
      "----------   Imbalanced Metrics   -------------------\n",
      " Classification report imbalanced:                    pre       rec       spe        f1       geo       iba       sup\n",
      "\n",
      "          0       0.99      1.00      0.08      1.00      0.29      0.09      1592\n",
      "          1       0.33      0.08      1.00      0.13      0.29      0.08        12\n",
      "\n",
      "avg / total       0.99      0.99      0.09      0.99      0.29      0.09      1604\n",
      "\n",
      " Sensitivity specificity support:\n",
      "(array([0.99874372, 0.08333333]), array([0.08333333, 0.99874372]), array([1592,   12]))\n",
      " Sensitivity score: 0.08333333333333333\n",
      " Specificity score: 0.9987437185929648\n",
      " Geometric mean score: 0.2884937490069419\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    from imblearn.under_sampling import RepeatedEditedNearestNeighbours\n",
    "    rebalance_train_test_logreg(X, y, RepeatedEditedNearestNeighbours(), 'RepeatedEditedNearestNeighbours',test_size)\n",
    "except:\n",
    "    print(\"Erro!\")\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# AllKNN"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------------------AllKNN test size=0.1--------------------------------------\n",
      "----------   Standard Metrics   -------------------\n",
      " Accuracy Score: 0.9918952618453866\n",
      " Precision Score: [0.99312929 0.33333333]\n",
      " Recall Score: [0.99874372 0.08333333]\n",
      "----------   Imbalanced Metrics   -------------------\n",
      " Classification report imbalanced:                    pre       rec       spe        f1       geo       iba       sup\n",
      "\n",
      "          0       0.99      1.00      0.08      1.00      0.29      0.09      1592\n",
      "          1       0.33      0.08      1.00      0.13      0.29      0.08        12\n",
      "\n",
      "avg / total       0.99      0.99      0.09      0.99      0.29      0.09      1604\n",
      "\n",
      " Sensitivity specificity support:\n",
      "(array([0.99874372, 0.08333333]), array([0.08333333, 0.99874372]), array([1592,   12]))\n",
      " Sensitivity score: 0.08333333333333333\n",
      " Specificity score: 0.9987437185929648\n",
      " Geometric mean score: 0.2884937490069419\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    from imblearn.under_sampling import AllKNN\n",
    "    rebalance_train_test_logreg(X, y, AllKNN(), 'AllKNN',test_size)\n",
    "except:\n",
    "    print(\"Erro!\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# InstanceHardnessThreshold"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------------------InstanceHardnessThreshold test size=0.1--------------------------------------\n",
      "----------   Standard Metrics   -------------------\n",
      " Accuracy Score: 0.9918952618453866\n",
      " Precision Score: [0.99374609 0.4       ]\n",
      " Recall Score: [0.99811558 0.16666667]\n",
      "----------   Imbalanced Metrics   -------------------\n",
      " Classification report imbalanced:                    pre       rec       spe        f1       geo       iba       sup\n",
      "\n",
      "          0       0.99      1.00      0.17      1.00      0.41      0.18      1592\n",
      "          1       0.40      0.17      1.00      0.24      0.41      0.15        12\n",
      "\n",
      "avg / total       0.99      0.99      0.17      0.99      0.41      0.18      1604\n",
      "\n",
      " Sensitivity specificity support:\n",
      "(array([0.99811558, 0.16666667]), array([0.16666667, 0.99811558]), array([1592,   12]))\n",
      " Sensitivity score: 0.16666666666666666\n",
      " Specificity score: 0.9981155778894473\n",
      " Geometric mean score: 0.40786345302675486\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    from imblearn.under_sampling import InstanceHardnessThreshold\n",
    "    rebalance_train_test_logreg(X, y, InstanceHardnessThreshold(), 'InstanceHardnessThreshold',test_size)\n",
    "except:\n",
    "    print(\"Erro!\")\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# NearMiss"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------------------NearMiss test size=0.1--------------------------------------\n",
      "----------   Standard Metrics   -------------------\n",
      " Accuracy Score: 0.08790523690773068\n",
      " Precision Score: [0.97777778 0.00612662]\n",
      " Recall Score: [0.08291457 0.75      ]\n",
      "----------   Imbalanced Metrics   -------------------\n",
      " Classification report imbalanced:                    pre       rec       spe        f1       geo       iba       sup\n",
      "\n",
      "          0       0.98      0.08      0.75      0.15      0.25      0.06      1592\n",
      "          1       0.01      0.75      0.08      0.01      0.25      0.07        12\n",
      "\n",
      "avg / total       0.97      0.09      0.75      0.15      0.25      0.06      1604\n",
      "\n",
      " Sensitivity specificity support:\n",
      "(array([0.08291457, 0.75      ]), array([0.75      , 0.08291457]), array([1592,   12]))\n",
      " Sensitivity score: 0.75\n",
      " Specificity score: 0.0829145728643216\n",
      " Geometric mean score: 0.2493710681860292\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    from imblearn.under_sampling import NearMiss\n",
    "    rebalance_train_test_logreg(X, y, NearMiss(), 'NearMiss',test_size)\n",
    "except:\n",
    "    print(\"Erro!\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# NeighbourhoodCleaningRule"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------------------NeighbourhoodCleaningRule test size=0.1--------------------------------------\n",
      "----------   Standard Metrics   -------------------\n",
      " Accuracy Score: 0.9918952618453866\n",
      " Precision Score: [0.99251404 0.        ]\n",
      " Recall Score: [0.99937186 0.        ]\n",
      "----------   Imbalanced Metrics   -------------------\n",
      " Classification report imbalanced:                    pre       rec       spe        f1       geo       iba       sup\n",
      "\n",
      "          0       0.99      1.00      0.00      1.00      0.00      0.00      1592\n",
      "          1       0.00      0.00      1.00      0.00      0.00      0.00        12\n",
      "\n",
      "avg / total       0.99      0.99      0.01      0.99      0.00      0.00      1604\n",
      "\n",
      " Sensitivity specificity support:\n",
      "(array([0.99937186, 0.        ]), array([0.        , 0.99937186]), array([1592,   12]))\n",
      " Sensitivity score: 0.0\n",
      " Specificity score: 0.9993718592964824\n",
      " Geometric mean score: 0.0\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    from imblearn.under_sampling import NeighbourhoodCleaningRule\n",
    "    rebalance_train_test_logreg(X, y, NeighbourhoodCleaningRule(), 'NeighbourhoodCleaningRule',test_size)\n",
    "except:\n",
    "    print(\"Erro!\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# OneSidedSelection"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------------------OneSidedSelection test size=0.1--------------------------------------\n",
      "----------   Standard Metrics   -------------------\n",
      " Accuracy Score: 0.9925187032418953\n",
      " Precision Score: [0.9925187 0.       ]\n",
      " Recall Score: [1. 0.]\n",
      "----------   Imbalanced Metrics   -------------------\n",
      " Classification report imbalanced:                    pre       rec       spe        f1       geo       iba       sup\n",
      "\n",
      "          0       0.99      1.00      0.00      1.00      0.00      0.00      1592\n",
      "          1       0.00      0.00      1.00      0.00      0.00      0.00        12\n",
      "\n",
      "avg / total       0.99      0.99      0.01      0.99      0.00      0.00      1604\n",
      "\n",
      " Sensitivity specificity support:\n",
      "(array([1., 0.]), array([0., 1.]), array([1592,   12]))\n",
      " Sensitivity score: 0.0\n",
      " Specificity score: 1.0\n",
      " Geometric mean score: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/pedro/Library/Python/3.7/lib/python/site-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/pedro/Library/Python/3.7/lib/python/site-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    from imblearn.under_sampling import OneSidedSelection\n",
    "    rebalance_train_test_logreg(X, y, OneSidedSelection(), 'OneSidedSelection',test_size)\n",
    "except:\n",
    "    print(\"Erro!\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# RandomUnderSampler"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------------------RandomUnderSampler test size=0.1--------------------------------------\n",
      "----------   Standard Metrics   -------------------\n",
      " Accuracy Score: 0.8391521197007481\n",
      " Precision Score: [0.99850523 0.03759398]\n",
      " Recall Score: [0.83919598 0.83333333]\n",
      "----------   Imbalanced Metrics   -------------------\n",
      " Classification report imbalanced:                    pre       rec       spe        f1       geo       iba       sup\n",
      "\n",
      "          0       1.00      0.84      0.83      0.91      0.84      0.70      1592\n",
      "          1       0.04      0.83      0.84      0.07      0.84      0.70        12\n",
      "\n",
      "avg / total       0.99      0.84      0.83      0.91      0.84      0.70      1604\n",
      "\n",
      " Sensitivity specificity support:\n",
      "(array([0.83919598, 0.83333333]), array([0.83333333, 0.83919598]), array([1592,   12]))\n",
      " Sensitivity score: 0.8333333333333334\n",
      " Specificity score: 0.8391959798994975\n",
      " Geometric mean score: 0.8362595190786059\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    from imblearn.under_sampling import RandomUnderSampler\n",
    "    rebalance_train_test_logreg(X, y, RandomUnderSampler(), 'RandomUnderSampler',test_size)\n",
    "except:\n",
    "    print(\"Erro!\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# TomekLinks"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------------------TomekLinks test size=0.1--------------------------------------\n",
      "----------   Standard Metrics   -------------------\n",
      " Accuracy Score: 0.9925187032418953\n",
      " Precision Score: [0.9925187 0.       ]\n",
      " Recall Score: [1. 0.]\n",
      "----------   Imbalanced Metrics   -------------------\n",
      " Classification report imbalanced:                    pre       rec       spe        f1       geo       iba       sup\n",
      "\n",
      "          0       0.99      1.00      0.00      1.00      0.00      0.00      1592\n",
      "          1       0.00      0.00      1.00      0.00      0.00      0.00        12\n",
      "\n",
      "avg / total       0.99      0.99      0.01      0.99      0.00      0.00      1604\n",
      "\n",
      " Sensitivity specificity support:\n",
      "(array([1., 0.]), array([0., 1.]), array([1592,   12]))\n",
      " Sensitivity score: 0.0\n",
      " Specificity score: 1.0\n",
      " Geometric mean score: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/pedro/Library/Python/3.7/lib/python/site-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/pedro/Library/Python/3.7/lib/python/site-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    from imblearn.under_sampling import TomekLinks\n",
    "    rebalance_train_test_logreg(X, y, TomekLinks(), 'TomekLinks',test_size)\n",
    "except:\n",
    "    print(\"Erro!\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# ADASYN"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------------------ADASYN test size=0.1--------------------------------------\n",
      "----------   Standard Metrics   -------------------\n",
      " Accuracy Score: 0.8653366583541147\n",
      " Precision Score: [0.99782923 0.04054054]\n",
      " Recall Score: [0.86620603 0.75      ]\n",
      "----------   Imbalanced Metrics   -------------------\n",
      " Classification report imbalanced:                    pre       rec       spe        f1       geo       iba       sup\n",
      "\n",
      "          0       1.00      0.87      0.75      0.93      0.81      0.66      1592\n",
      "          1       0.04      0.75      0.87      0.08      0.81      0.64        12\n",
      "\n",
      "avg / total       0.99      0.87      0.75      0.92      0.81      0.66      1604\n",
      "\n",
      " Sensitivity specificity support:\n",
      "(array([0.86620603, 0.75      ]), array([0.75      , 0.86620603]), array([1592,   12]))\n",
      " Sensitivity score: 0.75\n",
      " Specificity score: 0.8662060301507538\n",
      " Geometric mean score: 0.8060114903728516\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/pedro/Library/Python/3.7/lib/python/site-packages/sklearn/linear_model/_logistic.py:764: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    from imblearn.over_sampling import ADASYN\n",
    "    rebalance_train_test_logreg(X, y, ADASYN(), 'ADASYN',test_size)\n",
    "except:\n",
    "    print(\"Erro!\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# BorderlineSMOTE"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------------------BorderlineSMOTE test size=0.1--------------------------------------\n",
      "----------   Standard Metrics   -------------------\n",
      " Accuracy Score: 0.9270573566084788\n",
      " Precision Score: [0.996633   0.05882353]\n",
      " Recall Score: [0.92964824 0.58333333]\n",
      "----------   Imbalanced Metrics   -------------------\n",
      " Classification report imbalanced:                    pre       rec       spe        f1       geo       iba       sup\n",
      "\n",
      "          0       1.00      0.93      0.58      0.96      0.74      0.56      1592\n",
      "          1       0.06      0.58      0.93      0.11      0.74      0.52        12\n",
      "\n",
      "avg / total       0.99      0.93      0.59      0.96      0.74      0.56      1604\n",
      "\n",
      " Sensitivity specificity support:\n",
      "(array([0.92964824, 0.58333333]), array([0.58333333, 0.92964824]), array([1592,   12]))\n",
      " Sensitivity score: 0.5833333333333334\n",
      " Specificity score: 0.9296482412060302\n",
      " Geometric mean score: 0.7364066861253938\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/pedro/Library/Python/3.7/lib/python/site-packages/sklearn/linear_model/_logistic.py:764: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    from imblearn.over_sampling import BorderlineSMOTE\n",
    "    rebalance_train_test_logreg(X, y, BorderlineSMOTE(), 'BorderlineSMOTE',test_size)\n",
    "except:\n",
    "    print(\"Erro!\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# KMeansSMOTE"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Erro!\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    from imblearn.over_sampling import KMeansSMOTE\n",
    "    rebalance_train_test_logreg(X, y, KMeansSMOTE(), 'KMeansSMOTE',test_size)\n",
    "except:\n",
    "    print(\"Erro!\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# RandomOverSampler"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------------------RandomOverSampler test size=0.1--------------------------------------\n",
      "----------   Standard Metrics   -------------------\n",
      " Accuracy Score: 0.8591022443890274\n",
      " Precision Score: [0.99781341 0.0387931 ]\n",
      " Recall Score: [0.85992462 0.75      ]\n",
      "----------   Imbalanced Metrics   -------------------\n",
      " Classification report imbalanced:                    pre       rec       spe        f1       geo       iba       sup\n",
      "\n",
      "          0       1.00      0.86      0.75      0.92      0.80      0.65      1592\n",
      "          1       0.04      0.75      0.86      0.07      0.80      0.64        12\n",
      "\n",
      "avg / total       0.99      0.86      0.75      0.92      0.80      0.65      1604\n",
      "\n",
      " Sensitivity specificity support:\n",
      "(array([0.85992462, 0.75      ]), array([0.75      , 0.85992462]), array([1592,   12]))\n",
      " Sensitivity score: 0.75\n",
      " Specificity score: 0.8599246231155779\n",
      " Geometric mean score: 0.8030837237403604\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/pedro/Library/Python/3.7/lib/python/site-packages/sklearn/linear_model/_logistic.py:764: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    from imblearn.over_sampling import RandomOverSampler\n",
    "    rebalance_train_test_logreg(X, y, RandomOverSampler(), 'RandomOverSampler',test_size)\n",
    "except:\n",
    "    print(\"Erro!\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# SMOTE"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------------------SMOTE test size=0.1--------------------------------------\n",
      "----------   Standard Metrics   -------------------\n",
      " Accuracy Score: 0.8703241895261845\n",
      " Precision Score: [0.99784173 0.04205607]\n",
      " Recall Score: [0.87123116 0.75      ]\n",
      "----------   Imbalanced Metrics   -------------------\n",
      " Classification report imbalanced:                    pre       rec       spe        f1       geo       iba       sup\n",
      "\n",
      "          0       1.00      0.87      0.75      0.93      0.81      0.66      1592\n",
      "          1       0.04      0.75      0.87      0.08      0.81      0.65        12\n",
      "\n",
      "avg / total       0.99      0.87      0.75      0.92      0.81      0.66      1604\n",
      "\n",
      " Sensitivity specificity support:\n",
      "(array([0.87123116, 0.75      ]), array([0.75      , 0.87123116]), array([1592,   12]))\n",
      " Sensitivity score: 0.75\n",
      " Specificity score: 0.8712311557788944\n",
      " Geometric mean score: 0.8083460687318093\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/pedro/Library/Python/3.7/lib/python/site-packages/sklearn/linear_model/_logistic.py:764: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    from imblearn.over_sampling import SMOTE\n",
    "    rebalance_train_test_logreg(X, y, SMOTE(), 'SMOTE',test_size)\n",
    "except:\n",
    "    print(\"Erro!\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# SMOTENC"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Erro!\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    from imblearn.over_sampling import SMOTENC\n",
    "    rebalance_train_test_logreg(X, y, SMOTENC(), 'SMOTENC',test_size)\n",
    "except:\n",
    "    print(\"Erro!\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# SVMSMOTE"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------------------SVMSMOTE test size=0.1--------------------------------------\n",
      "----------   Standard Metrics   -------------------\n",
      " Accuracy Score: 0.933291770573566\n",
      " Precision Score: [0.99665552 0.06422018]\n",
      " Recall Score: [0.93592965 0.58333333]\n",
      "----------   Imbalanced Metrics   -------------------\n",
      " Classification report imbalanced:                    pre       rec       spe        f1       geo       iba       sup\n",
      "\n",
      "          0       1.00      0.94      0.58      0.97      0.74      0.57      1592\n",
      "          1       0.06      0.58      0.94      0.12      0.74      0.53        12\n",
      "\n",
      "avg / total       0.99      0.93      0.59      0.96      0.74      0.56      1604\n",
      "\n",
      " Sensitivity specificity support:\n",
      "(array([0.93592965, 0.58333333]), array([0.58333333, 0.93592965]), array([1592,   12]))\n",
      " Sensitivity score: 0.5833333333333334\n",
      " Specificity score: 0.9359296482412061\n",
      " Geometric mean score: 0.738890358222407\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/pedro/Library/Python/3.7/lib/python/site-packages/sklearn/linear_model/_logistic.py:764: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    from imblearn.over_sampling import SVMSMOTE\n",
    "    rebalance_train_test_logreg(X, y, SVMSMOTE(), 'SVMSMOTE',test_size)\n",
    "except:\n",
    "    print(\"Erro!\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# SMOTEENN"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------------------SMOTEENN test size=0.1--------------------------------------\n",
      "----------   Standard Metrics   -------------------\n",
      " Accuracy Score: 0.8653366583541147\n",
      " Precision Score: [0.99782923 0.04054054]\n",
      " Recall Score: [0.86620603 0.75      ]\n",
      "----------   Imbalanced Metrics   -------------------\n",
      " Classification report imbalanced:                    pre       rec       spe        f1       geo       iba       sup\n",
      "\n",
      "          0       1.00      0.87      0.75      0.93      0.81      0.66      1592\n",
      "          1       0.04      0.75      0.87      0.08      0.81      0.64        12\n",
      "\n",
      "avg / total       0.99      0.87      0.75      0.92      0.81      0.66      1604\n",
      "\n",
      " Sensitivity specificity support:\n",
      "(array([0.86620603, 0.75      ]), array([0.75      , 0.86620603]), array([1592,   12]))\n",
      " Sensitivity score: 0.75\n",
      " Specificity score: 0.8662060301507538\n",
      " Geometric mean score: 0.8060114903728516\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/pedro/Library/Python/3.7/lib/python/site-packages/sklearn/linear_model/_logistic.py:764: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    from imblearn.combine import SMOTEENN\n",
    "    rebalance_train_test_logreg(X, y, SMOTEENN(), 'SMOTEENN',test_size)\n",
    "except:\n",
    "    print(\"Erro!\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# SMOTETomek"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------------------SMOTETomek test size=0.1--------------------------------------\n",
      "----------   Standard Metrics   -------------------\n",
      " Accuracy Score: 0.8678304239401496\n",
      " Precision Score: [0.9978355 0.0412844]\n",
      " Recall Score: [0.86871859 0.75      ]\n",
      "----------   Imbalanced Metrics   -------------------\n",
      " Classification report imbalanced:                    pre       rec       spe        f1       geo       iba       sup\n",
      "\n",
      "          0       1.00      0.87      0.75      0.93      0.81      0.66      1592\n",
      "          1       0.04      0.75      0.87      0.08      0.81      0.64        12\n",
      "\n",
      "avg / total       0.99      0.87      0.75      0.92      0.81      0.66      1604\n",
      "\n",
      " Sensitivity specificity support:\n",
      "(array([0.86871859, 0.75      ]), array([0.75      , 0.86871859]), array([1592,   12]))\n",
      " Sensitivity score: 0.75\n",
      " Specificity score: 0.8687185929648241\n",
      " Geometric mean score: 0.8071796235805374\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/pedro/Library/Python/3.7/lib/python/site-packages/sklearn/linear_model/_logistic.py:764: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    from imblearn.combine import SMOTETomek\n",
    "    rebalance_train_test_logreg(X, y, SMOTETomek(), 'SMOTETomek',test_size)\n",
    "except:\n",
    "    print(\"Erro!\")\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# BalancedBaggingClassifier"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Erro!\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    from imblearn.ensemble import BalancedBaggingClassifier\n",
    "    rebalance_train_test_logreg(X, y, BalancedBaggingClassifier(), 'BalancedBaggingClassifier',test_size)\n",
    "except:\n",
    "    print(\"Erro!\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# BalancedRandomForestClassifier"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Erro!\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    from imblearn.ensemble import BalancedRandomForestClassifier\n",
    "    rebalance_train_test_logreg(X, y, BalancedRandomForestClassifier(), 'BalancedRandomForestClassifier',test_size)\n",
    "except:\n",
    "    print(\"Erro!\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# EasyEnsemble"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Erro!\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    from imblearn.ensemble import EasyEnsembleClassifier\n",
    "    rebalance_train_test_logreg(X, y, EasyEnsembleClassifier(), 'EasyEnsembleClassifier',test_size)\n",
    "except:\n",
    "    print(\"Erro!\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# RUSBoostClassifier"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Erro!\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    from imblearn.ensemble import RUSBoostClassifier\n",
    "    rebalance_train_test_logreg(X, y, RUSBoostClassifier(), 'RUSBoostClassifier',test_size)\n",
    "except:\n",
    "    print(\"Erro!\")\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# RUSBoostClassifier"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Erro!\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    from imblearn.ensemble import RUSBoostClassifier\n",
    "    rebalance_train_test_logreg(X, y, RUSBoostClassifier(), 'RUSBoostClassifier',test_size)\n",
    "except:\n",
    "    print(\"Erro!\")\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  },
  "pycharm": {
   "stem_cell": {
    "cell_type": "raw",
    "source": [
     "\n"
    ],
    "metadata": {
     "collapsed": false
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}